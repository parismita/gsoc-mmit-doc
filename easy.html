<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Parismita Das" />

<meta name="date" content="2018-01-11" />

<title>Train and test a decision tree model</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Test solutions</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Overview</a>
</li>
<li>
  <a href="easy.html">Easy</a>
</li>
<li>
  <a href="medium.html">Medium</a>
</li>
<li>
  <a href="hard.html">Hard</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Train and test a decision tree model</h1>
<h3 class="subtitle"><em>Easy</em></h3>
<h4 class="author"><em>Parismita Das</em></h4>
<h4 class="date"><em>11 January 2018</em></h4>

</div>


<p>To run train and test a decision tree model using rpart and partykit. And Using 5-fold cross-validation to compare the learned decision tree models to a trivial baseline learner.</p>
<div id="using-rpart" class="section level2">
<h2>Using rpart</h2>
<p>Importing libraries</p>
<pre><code>## Loading required package: grid</code></pre>
<pre><code>## Loading required package: libcoin</code></pre>
<pre><code>## Loading required package: mvtnorm</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<p>The dataset using is segmentationData of caret package. The following code seperates test and train data and removes “Case” column from dataset.</p>
<pre class="r"><code>data(&quot;segmentationData&quot;, package = &quot;caret&quot;)
segmentationData$Cell&lt;-NULL
train&lt;-subset(segmentationData,Case==&quot;Train&quot;)
test&lt;-subset(segmentationData,Case==&quot;Test&quot;)
train$Case&lt;-NULL
test$Case&lt;-NULL</code></pre>
<p>In the dataset, the target data to pe predicted is “Class” with two classes as “PS” and “WS”. The formula required for creating tree using rpart consist of all features expt y,time,status as given below</p>
<pre class="r"><code>form &lt;- Class ~ . - Class</code></pre>
<div id="the-trivial-baseline" class="section level3">
<h3>The trivial baseline</h3>
<p>Creating trivial desicion tree, keeping xval=0 signifies no cross-validation implemented.</p>
<pre class="r"><code>ctrl &lt;- rpart.control(minsplit = 15, minbucket = 5, xval=0)
tree &lt;- rpart(formula = form, data = train, na.action = na.rpart, control = ctrl, method = &quot;class&quot;)</code></pre>
<p>The desicion tree formed is:</p>
<p><img src="easy_files/figure-html/tree2-1.png" width="672" /></p>
<p>Predicting the target class and calculating the missclassification error:</p>
<pre class="r"><code>out&lt;-predict(tree,test)
status_predicted&lt;- colnames(out)[max.col(out, ties.method = c(&quot;first&quot;))] # predicted
status_input&lt;- as.character (test$Class) # actuals
mn&lt;- mean (status_input != status_predicted) # misclassification %</code></pre>
<p>Hence the error of misclassification is:</p>
<pre><code>## [1] &quot;error:  21.2871287128713 %&quot;</code></pre>
</div>
<div id="desicion-tree-model-using-cross-validation" class="section level3">
<h3>Desicion tree model using cross validation</h3>
<p>Creating desicion tree, using xval=5 which means 5-fold cross-validation implemented.</p>
<pre class="r"><code>ctrl &lt;- rpart.control(minsplit = 15, minbucket = 5, xval=5)
tree &lt;- rpart(formula = form, data = train, na.action = na.rpart, control = ctrl, method = &quot;class&quot;)</code></pre>
<p>The complexity parameter (cp) is used to control the size of the decision tree and to select the optimal tree size. Hence plotting cross validation error vs cp</p>
<p><img src="easy_files/figure-html/tree6-1.png" width="672" /></p>
<pre><code>## 
## Classification tree:
## rpart(formula = form, data = train, na.action = na.rpart, method = &quot;class&quot;, 
##     control = ctrl)
## 
## Variables actually used in tree construction:
##  [1] AvgIntenCh1            AvgIntenCh4            ConvexHullAreaRatioCh1
##  [4] EqEllipseOblateVolCh1  FiberWidthCh1          IntenCoocASMCh3       
##  [7] KurtIntenCh3           LengthCh1              NeighborMinDistCh1    
## [10] ShapeP2ACh1            TotalIntenCh2          VarIntenCh4           
## 
## Root node error: 373/1009 = 0.36967
## 
## n= 1009 
## 
##          CP nsplit rel error  xerror     xstd
## 1  0.329759      0   1.00000 1.00000 0.041108
## 2  0.160858      1   0.67024 0.69705 0.037245
## 3  0.034853      2   0.50938 0.59517 0.035278
## 4  0.029491      3   0.47453 0.55496 0.034389
## 5  0.018767      4   0.44504 0.55228 0.034327
## 6  0.017426      5   0.42627 0.52279 0.033626
## 7  0.016086      7   0.39142 0.53619 0.033950
## 8  0.012511      9   0.35925 0.55228 0.034327
## 9  0.010724     12   0.32172 0.57373 0.034813
## 10 0.010000     15   0.28954 0.57373 0.034813</code></pre>
<p>Pruning the tree using cross validation to prevent overfitting, Thus inappropriate nodes are removed</p>
<pre class="r"><code>pdtree&lt;- prune(tree, cp=tree$cptable[which.min(tree$cptable[,&quot;xerror&quot;]),&quot;CP&quot;])</code></pre>
<p><img src="easy_files/figure-html/plot2-1.png" width="672" /></p>
<p>The plots of the r-square (apparent and apparent - from cross-validation) versus the number of splits. And the Relative Error(cross-validation) +/- 1-SE from cross-validation versus the number of splits.</p>
<pre><code>## 
## Classification tree:
## rpart(formula = form, data = train, na.action = na.rpart, method = &quot;class&quot;, 
##     control = ctrl)
## 
## Variables actually used in tree construction:
## [1] AvgIntenCh1            ConvexHullAreaRatioCh1 FiberWidthCh1         
## [4] IntenCoocASMCh3        TotalIntenCh2         
## 
## Root node error: 373/1009 = 0.36967
## 
## n= 1009 
## 
##         CP nsplit rel error  xerror     xstd
## 1 0.329759      0   1.00000 1.00000 0.041108
## 2 0.160858      1   0.67024 0.69705 0.037245
## 3 0.034853      2   0.50938 0.59517 0.035278
## 4 0.029491      3   0.47453 0.55496 0.034389
## 5 0.018767      4   0.44504 0.55228 0.034327
## 6 0.017426      5   0.42627 0.52279 0.033626</code></pre>
<pre><code>## Warning in rsq.rpart(pdtree): may not be applicable for this method</code></pre>
<p><img src="easy_files/figure-html/pred5-1.png" width="672" /></p>
<p>Predicting the target class and calculating the missclassification error for pruned tree:</p>
<pre class="r"><code>out&lt;-predict(pdtree,test)
status_predicted&lt;- colnames(out)[max.col(out, ties.method = c(&quot;first&quot;))] # predicted
status_input&lt;- as.character (test$Class) # actuals
mn&lt;- mean (status_input != status_predicted) # misclassification %</code></pre>
<p>Hence the error of misclassification is:</p>
<pre><code>## [1] &quot;error:  20.8910891089109 %&quot;</code></pre>
<p>Hence the misclassification error decreased on using k-fold cross-validation.</p>
</div>
</div>
<div id="using-partykit" class="section level2">
<h2>Using partykit</h2>
<p>Using conditional trees to train the desicion tree model</p>
<pre class="r"><code>ctrl &lt;- ctree_control(teststat = &quot;quad&quot;,minsplit = 40, minbucket = 20)
tree &lt;- ctree(formula = form, data = train, control = ctrl, method = &quot;class&quot;)</code></pre>
<p>The desicion tree :</p>
<p><img src="easy_files/figure-html/ptk2-1.png" width="672" /></p>
<p>Predicting target value and calculating the misclassification error:</p>
<pre class="r"><code>#Model Testing
out&lt;-predict(tree,test,type = &quot;prob&quot;)
status_predicted&lt;- colnames(out)[max.col(out, ties.method = c(&quot;first&quot;))] # predicted
status_input&lt;- as.character (test$Class) # actuals
m &lt;- mean (status_input != status_predicted) # misclassification %
print(m)</code></pre>
<pre><code>## [1] 0.2267327</code></pre>
<p>Estimated conditional class probabilities depending on the first split variable. And plotting the same:</p>
<pre class="r"><code>prob &lt;- predict(tree,test, type = &quot;prob&quot;)[,1] + runif(nrow(test), min = -0.01, max = 0.01)
splitvar &lt;- character_split(split_node(node_party(tree)), data = data_party(tree))$name
plot(test[[splitvar]], prob, pch = as.numeric(test$Class), ylab = &quot;Conditional Class Prob.&quot;,xlab = splitvar)
abline(v = split_node(node_party(tree))$breaks, lty = 2)
legend(0.15, 0.7, pch = 1:2, legend = levels(test$Class), bty = &quot;n&quot;)</code></pre>
<p><img src="easy_files/figure-html/ptk4-1.png" width="672" /></p>
</div>
<div id="trtf" class="section level2">
<h2>Trtf</h2>
<pre><code>## Loading required package: mlt</code></pre>
<pre><code>## Loading required package: basefun</code></pre>
<pre><code>## Loading required package: variables</code></pre>
<pre><code>## 
## Attaching package: &#39;variables&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     unit</code></pre>
<pre><code>## The following object is masked from &#39;package:grid&#39;:
## 
##     unit</code></pre>
<pre><code>## 
## Attaching package: &#39;survival&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:caret&#39;:
## 
##     cluster</code></pre>
<p>Using interval censored data neuroblastomaProcessed of penaltyLearning package. The interval is consisted in target.mat and feature.mat consist of the features to be trained on.</p>
<pre class="r"><code>data(neuroblastomaProcessed, package=&quot;penaltyLearning&quot;)</code></pre>
<p>Considering the datapoints where interval is finite(there is no [-Inf, Inf] intervaled data).</p>
<pre class="r"><code>finite.targets &lt;- with(neuroblastomaProcessed, {
  data.frame(log.penalty=target.mat[is.finite(target.mat)])
})</code></pre>
<p>Creating ctm object later used to fit using mlt.</p>
<pre class="r"><code>m &lt;- ctm(as.basis(~log.penalty, data=finite.targets), todistr=&quot;Normal&quot;)</code></pre>
<p>Creating survival object, as response variable for model.</p>
<pre class="r"><code>train.Surv &lt;- with(neuroblastomaProcessed, { Surv(target.mat[, 1], target.mat[,2], type=&quot;interval2&quot;)})</code></pre>
<p>Creating training set, fitting ctm object to mlt and trtf trafotree.</p>
<pre class="r"><code>train.df &lt;- data.frame(log.penalty=train.Surv, neuroblastomaProcessed$feature.mat)
mlt.fit &lt;- mlt(m, data=train.df)
tree.fit &lt;- trafotree(m, formula = log.penalty ~ ., data=train.df, mltargs=list(theta=coef(mlt.fit)))</code></pre>
<p>Create tree using partykit</p>
<pre class="r"><code>node_party(tree.fit) # 19-node tree.</code></pre>
<pre><code>## [1] root
## |   [2] V19 &lt;= 265.69344
## |   |   [3] V12 &lt;= 0
## |   |   |   [4] V35 &lt;= 2.35227
## |   |   |   |   [5] V96 &lt;= 0
## |   |   |   |   |   [6] V24 &lt;= 1.87282
## |   |   |   |   |   |   [7] V37 &lt;= 1.39945
## |   |   |   |   |   |   |   [8] V17 &lt;= 2.50753
## |   |   |   |   |   |   |   |   [9] V112 &lt;= 0 *
## |   |   |   |   |   |   |   |   [10] V112 &gt; 0 *
## |   |   |   |   |   |   |   [11] V17 &gt; 2.50753 *
## |   |   |   |   |   |   [12] V37 &gt; 1.39945 *
## |   |   |   |   |   [13] V24 &gt; 1.87282 *
## |   |   |   |   [14] V96 &gt; 0 *
## |   |   |   [15] V35 &gt; 2.35227
## |   |   |   |   [16] V34 &lt;= 10.98913 *
## |   |   |   |   [17] V34 &gt; 10.98913 *
## |   |   [18] V12 &gt; 0 *
## |   [19] V19 &gt; 265.69344 *</code></pre>
<p>Plotting the tree: <img src="easy_files/figure-html/trtf7-1.png" width="672" /></p>
<p>Predicting the response and calculating the error of miscalculation. Here, the error is defined as the average value of predicted data that doesnt fall into the interval of target.mat</p>
<pre class="r"><code>##prediction
pred.vec &lt;- predict(tree.fit)
pred.log.penalty &lt;- tree.fit$coef[names(pred.vec), &quot;(Intercept)&quot;]
is.lo &lt;- pred.log.penalty &lt; neuroblastomaProcessed$target.mat[, 1]
is.hi &lt;- neuroblastomaProcessed$target.mat[, 2] &lt; pred.log.penalty
is.error &lt;- is.lo | is.hi
mn&lt;- mean(is.error)</code></pre>
<p>The error is :</p>
<pre><code>## [1] 0.2358104</code></pre>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
